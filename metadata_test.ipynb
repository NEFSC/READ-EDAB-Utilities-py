{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2e17ad",
   "metadata": {},
   "source": [
    "# Demo Notebook to Test Metadata Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ccdc33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import xarray as xr\n",
    "import socket\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dcfc414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default utilities path: /Users/kimberly.hyde/Documents/nadata/python\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_python_path():\n",
    "    hostname = socket.gethostname()                                 # 1. Identify the computer by hostname\n",
    "    code_locations = {                                              # 2. Set default Python code location based on hostname\n",
    "        \"NECMAC04363461.local\": \"/Users/kimberly.hyde/Documents/\",  # Mac laptop\n",
    "        \"nefscsatdata\": \"/mnt/EDAB_Archive/\",                       # Satdata\n",
    "        \"guihyde\": \"/mnt/EDAB_Archive/\"                             # Kim's Satdata container\n",
    "    }\n",
    "\n",
    "    base_path = code_locations.get(hostname)\n",
    "    if not base_path:\n",
    "        print(f\"Unknown hostname: {hostname}\")\n",
    "        return None\n",
    "\n",
    "    default_utility_path = Path(base_path) / \"nadata/python\"\n",
    "    if not default_utility_path.is_dir():\n",
    "        print(f\"Directory not found: {default_utility_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Default utilities path: {default_utility_path}\")\n",
    "    return default_utility_path\n",
    "\n",
    "python_path = get_python_path()\n",
    "if str(python_path) not in sys.path:\n",
    "    sys.path.insert(0, str(python_path))\n",
    "\n",
    "from utilities import date_utilities, gridding_utilities, file_utilities, import_utilities, calc_daylength, metadata_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156e9d0e",
   "metadata": {},
   "source": [
    "## Read Metadata Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d618a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     TAG                                              VALUE  \\\n",
      "0            Conventions                          CF-1.11, COARDS, ACDD-1.3   \n",
      "1  Metadata _Conventions                     Unidata Dataset Discovery v1.0   \n",
      "2        acknowledgement  The data are sponsored by NOAA and may be free...   \n",
      "3            institution  DOC | NOAA | National Marine Fisheries Service...   \n",
      "4           creator_type                                             person   \n",
      "\n",
      "  Name Email  URL Initials geospatial_bounds summary history Dataset  ...  \\\n",
      "0  NaN   NaN  NaN      NaN               NaN     NaN     NaN     NaN  ...   \n",
      "1  NaN   NaN  NaN      NaN               NaN     NaN     NaN     NaN  ...   \n",
      "2  NaN   NaN  NaN      NaN               NaN     NaN     NaN     NaN  ...   \n",
      "3  NaN   NaN  NaN      NaN               NaN     NaN     NaN     NaN  ...   \n",
      "4  NaN   NaN  NaN      NaN               NaN     NaN     NaN     NaN  ...   \n",
      "\n",
      "  units valid_min valid_max comment reference wavelengths plot_title plot_min  \\\n",
      "0   NaN       NaN       NaN     NaN       NaN         NaN        NaN      NaN   \n",
      "1   NaN       NaN       NaN     NaN       NaN         NaN        NaN      NaN   \n",
      "2   NaN       NaN       NaN     NaN       NaN         NaN        NaN      NaN   \n",
      "3   NaN       NaN       NaN     NaN       NaN         NaN        NaN      NaN   \n",
      "4   NaN       NaN       NaN     NaN       NaN         NaN        NaN      NaN   \n",
      "\n",
      "  plot_max plot_log  \n",
      "0      NaN      NaN  \n",
      "1      NaN      NaN  \n",
      "2      NaN      NaN  \n",
      "3      NaN      NaN  \n",
      "4      NaN      NaN  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "from utilities import get_python_dir\n",
    "\n",
    "dir = get_python_dir(resources=True)\n",
    "metapath = os.path.join(dir,'metadata','EDAB_metadata.xlsx')\n",
    "\n",
    "metadict = pd.read_excel(metapath,sheet_name=None)\n",
    "allmeta = pd.concat(metadict.values(), ignore_index=True)\n",
    "print(allmeta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata_lookup(excel_path: str) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Reads an Excel file with multiple sheets containing metadata mappings.\n",
    "    Returns a dictionary: {sheet_name: {attribute_name: value, ...}, ...}\n",
    "    \"\"\"\n",
    "    metadata_dict = {}\n",
    "    xls = pd.ExcelFile(excel_path)\n",
    "    for sheet in xls.sheet_names:\n",
    "        df = xls.parse(sheet)\n",
    "        # Assumes two columns: 'Attribute' and 'Value'\n",
    "        if 'Attribute' in df.columns and 'Value' in df.columns:\n",
    "            metadata_dict[sheet] = dict(zip(df['Attribute'], df['Value']))\n",
    "        else:\n",
    "            raise ValueError(f\"Sheet '{sheet}' must contain 'Attribute' and 'Value' columns.\")\n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8093a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_netcdf_metadata(nc_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extracts global attributes from a NetCDF file.\n",
    "    \"\"\"\n",
    "    with xr.open_dataset(nc_path) as ds:\n",
    "        return dict(ds.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_netcdf_metadata(nc_path: str, updates: Dict[str, Any], output_path: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Updates or adds global attributes in a NetCDF file.\n",
    "    Writes to output_path if provided, otherwise overwrites original.\n",
    "    \"\"\"\n",
    "    output_path = output_path or nc_path\n",
    "    with xr.open_dataset(nc_path) as ds:\n",
    "        ds.attrs.update(updates)\n",
    "        ds.to_netcdf(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_metadata_updates(nc_path: str, excel_path: str, sheet: str = 'global', output_path: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Wrapper to apply metadata updates from a specific sheet in the Excel file to a NetCDF file.\n",
    "    \"\"\"\n",
    "    metadata_lookup = read_metadata_lookup(excel_path)\n",
    "    if sheet not in metadata_lookup:\n",
    "        raise KeyError(f\"Sheet '{sheet}' not found in Excel file.\")\n",
    "    \n",
    "    updates = metadata_lookup[sheet]\n",
    "    update_netcdf_metadata(nc_path, updates, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fddee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_metadata_updates(\n",
    "    nc_path=\"data.nc\",\n",
    "    excel_path=\"metadata_lookup.xlsx\",\n",
    "    sheet=\"global\",  # or any other sheet name\n",
    "    output_path=\"data_updated.nc\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
